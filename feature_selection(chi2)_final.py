# -*- coding: utf-8 -*-
"""feature_selection(chi2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BOtrTgThZ5agQyk5GZO0PheYqSkD1z6C
"""

#importing libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
from tensorflow.keras.regularizers import l2
from sklearn.feature_selection import SelectKBest, chi2
import tensorflow as tf
import seaborn as sns
import matplotlib.pyplot as plt

# Read the databases from resources
health_factors = pd.read_csv("/content/Health_Risk_factors.csv")
agriculture = pd.read_csv("/content/agricultural_inputs.csv")
climate = pd.read_csv("/content/climate.csv")
freshwater = pd.read_csv("/content/freshwater.csv")
health_system = pd.read_csv("/content/health_system.csv")

hf = health_factors.rename(columns={
    "Incidence of tuberculosis  per 100,000 people 2018": "tuberculosis",
    "Prevalence of HIV Total % of population ages 15-49 2018": "HIV_total",
    "Prevalence of HIV Women's share of population ages 15+ living with HIV % 2018": "HIV_female",
    "Prevalence of HIV Youth, Male % of population ages 15-24 2018": "HIV_youth_male",
    "Prevalence of HIV Youth, Female % of population ages 15-24 2018": "HIV_youth_female",
    "Prevalence of diabetes  % of population ages 20 to 79 2019": "diabetes",
    "Cause of death Communicable diseases and maternal, prenatal, and nutrition conditions % of population 2016":"Diseases_death",
})
hs = health_system.rename(columns={
    'External health expenditure (% of current health expenditure)   2016': "ext_health_expend",
    "Health expenditure Public % of current 2016": "public_health_expend",
    "Health workers Physicians per 1,000 people 2009-18": "physicians",
    "Health workers Nurses and midwives per 1,000 people 2009-18": "nurses",
    "Specialist surgical workforce  per 100,000 population 2008-18": "surgeries"
     })
fw = freshwater.rename(columns={
    'Annual freshwater withdrawals  % for agriculture 2015': "water_agriculture",
    "People using at least basic drinking water services Urban % of urban population 2018": "water_urban",
    "People using at least basic drinking water services Rural % of Rural population 2018": "water_rural",})
cl = climate.rename(columns={
    'Resilience Disaster risk reduction progress score 1, worst to 5,best 2011':"Disaster_risk",
    'Exposure to impact Urban population living in areas where elevation is below 5 meters % of urban population 2010':"urban_population",
    'Exposure to impact Population affected by droughts, floods, and extreme temperatures average annual; % of total population 2009':"climet_affected_population"
})
ag = agriculture.rename(columns={
    'Fertilizer consumption  kilograms per hectare of arable land 2014-16': "fertilizer",
    "Agricultural employment  % of total employment 2000-02": "farmers_2000",
    "Agricultural employment  % of total employment 2014-16": "farmers_recent",
    "Agricultural machinery tractors per 100 sq. km of arable land 2009": "agricultur_machinery"})

merged_df = pd.concat([hf[[ "HIV_total","HIV_female", 'Diseases_death',"HIV_youth_male","HIV_youth_female", "diabetes",'tuberculosis']],
                      hs[['ext_health_expend', 'public_health_expend', 'physicians', 'nurses', 'surgeries']],
                      fw[[ "water_agriculture",'water_urban', 'water_rural']],
                      cl[[ "Disaster_risk",'climet_affected_population',"urban_population"]],
                      ag[['fertilizer', 'farmers_2000', 'farmers_recent', "agricultur_machinery"]]],
                     axis=1)

merged_df.columns

merged_df.describe()

#df1 = ag.replace('', np.nan)  # Replace empty values with NaN
# df1 = merged_df.dropna()  # Drop rows with any missing values
column_means = merged_df.mean()
df1 = merged_df.fillna(column_means)
df1.describe()

# Define the thresholds for classification

threshold_tuberculosis = 100
# Create a DataFrame to store the classified values
df2 = pd.DataFrame()
# Classify every columns
df2 = df1.drop('tuberculosis', axis=1).copy()
df2['tuberculosis'] = [0 if i < threshold_tuberculosis else 1 for i in df1['tuberculosis']]

# Extract X and y
y = df2['tuberculosis'].values
X1 = df2.drop(columns='tuberculosis').values
df2.shape

# Split the preprocessed data into a training and testing dataset
X1_train1, X1_test, y_train, y_test = train_test_split(X1, y,random_state=1,stratify=y,test_size=.2)

# from sklearn.feature_selection import RFE
# from sklearn.linear_model import LogisticRegression  # or any other model

# # Assuming X_train and y_train are your training data and labels
# n_features_to_select = 5  # Select the top 10 features
# estimator = LogisticRegression()  # You can choose any model here
# rfe = RFE(estimator=estimator, n_features_to_select=n_features_to_select)
# X_train_selected = rfe.fit_transform(X_train1, y_train)

k_best = 20  # Select the top 5 features
selector = SelectKBest(score_func=chi2, k=k_best)
X1_train = selector.fit_transform(X1_train1, y_train)
X1_test = selector.transform(X1_test)

selected_features_mask = selector.get_support()

# Get the column names of the selected features
selected_feature_names = df2.drop(columns='tuberculosis').columns[selected_features_mask]

# Get the p-values of each feature
p_values = selector.pvalues_[selected_features_mask]

# Create a DataFrame to store the results
result_df = pd.DataFrame({
    'Feature': selected_feature_names,
    'P-Value': p_values
})

# Sort the DataFrame based on the p-values in ascending order
result_df = result_df.sort_values(by='P-Value')

# Reset the index of the DataFrame
result_df = result_df.reset_index(drop=True)

# Print the result DataFrame
print(result_df)

X = df2[["surgeries","Diseases_death", "fertilizer", "agricultur_machinery", "farmers_recent", "ext_health_expend", "farmers_2000"]].values
X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1,stratify=y,test_size=.2)

# import pandas as pd
# from sklearn.feature_selection import RFE
# from sklearn.linear_model import LogisticRegression

# # Assuming n_features_to_select = 10 and estimator = LogisticRegression() as mentioned in your code
# rfe = RFE(estimator=LogisticRegression(), n_features_to_select=10)
# X_train_selected = rfe.fit_transform(X_train1, y_train)

# # Get the selected feature indices
# selected_feature_indices = rfe.support_

# # Get the column names of the selected features
# selected_feature_names = df2.drop(columns='tuberculosis').columns[selected_feature_indices]

# # Create a DataFrame to store the results
# result_df = pd.DataFrame({
#     'Feature': selected_feature_names,
#     'Ranking': rfe.ranking_[selected_feature_indices]
# })

# # Sort the DataFrame based on the ranking in ascending order
# result_df = result_df.sort_values(by='Ranking')

# # Reset the index of the DataFrame
# result_df = result_df.reset_index(drop=True)

# # Print the result DataFrame
# print(result_df)

# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.
l_1 = 50
l_2 = 50
input_features = len(X_train[0])
nn = tf.keras.models.Sequential()

# First hidden layer
nn.add(tf.keras.layers.Dense(units=l_1, input_dim = input_features, activation = "tanh"))

# Second hidden layer
nn.add(tf.keras.layers.Dense(units=l_2, activation = "LeakyReLU"))

# Output layer
nn.add(tf.keras.layers.Dense(units=1, activation="sigmoid"))

# Check the structure of the model
nn.summary()

# Compile the model
nn.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])

# Train the model
nn.fit(X_train, y_train, epochs=50)

# Evaluate the model using the test data
model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)
print(f"Loss: {model_loss}, Accuracy: {model_accuracy}")

from sklearn.feature_selection import SelectKBest, chi2

# k_best = 5  # Select the top 5 features
# selector = SelectKBest(score_func=chi2, k=k_best)
# selector.fit(X_train, y_train)
# selected_feature_indices = selector.get_support(indices=True)

# # Select the top k_best features for both X_train and X_test
# X_train_selected = X_train1[:, selected_feature_indices]
# X_test_selected = X_test[:, selected_feature_indices]

# # Define the model - deep neural net
# nn = tf.keras.models.Sequential()

# # ... (same as before)

# nn.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])

# # Fit the model with X_train_selected (after feature selection) and y_train
# nn.fit(X_train_selected, y_train, epochs=70)

# # Evaluate the model using the preprocessed test data
# model_loss, model_accuracy = nn.evaluate(X_test_selected, y_test, verbose=2)
# print(f"Loss: {model_loss}, Accuracy: {model_accuracy}")

y_pred = nn.predict(X_test)

# The predictions will be in the form of probabilities, so you might want to round them to get class labels (0 or 1)
y_pred_class = y_pred.round()
# Calculate the accuracy of the predictions
correct_predictions = (y_pred_class == y_test.reshape(-1, 1)).sum()
total_samples = len(y_test)
accuracy = correct_predictions / total_samples
print("Accuracy:", accuracy)

# Print the classification report
print("Classification Report:")
print(classification_report(y_test, y_pred_class))

import pandas as pd
from IPython.display import display

# Assuming df2 is your original DataFrame
X_df = pd.DataFrame(X, columns=["surgeries", "Diseases_death", "fertilizer", "agricultur_machinery", "farmers_recent", "ext_health_expend", "farmers_2000"])

# Get the summary statistics using describe()
summary_stats = X_df.describe()

# Display the table
display(summary_stats)















